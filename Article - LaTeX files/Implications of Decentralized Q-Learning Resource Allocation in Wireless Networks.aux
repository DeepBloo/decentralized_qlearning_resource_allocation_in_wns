\relax 
\citation{nie1999qlearning,maghsudi2015joint}
\citation{nie1999qlearning}
\citation{bennis2010q}
\citation{sutton1998reinforcement,watkins1992q}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Decentralized Stateless Q-learning for enhancing Spatial Reuse in a WN}{1}}
\newlabel{section:qlearning}{{II}{1}}
\citation{sutton1998reinforcement}
\newlabel{eq:ql_reward_policy}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}System model}{2}}
\newlabel{section:system_model}{{III}{2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Stateless Q-learning\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:qlearning}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Channel modelling}{2}}
\newlabel{section:channel_modelling}{{\unhbox \voidb@x \hbox {III-A}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Throughput calculation}{2}}
\newlabel{section:throughput_calculation}{{\unhbox \voidb@x \hbox {III-B}}{2}}
\newlabel{eq:shannon_capacity}{{1}{2}}
\newlabel{eq:sinr}{{1}{2}}
\citation{bellalta2016ax}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Reinforcement Learning Considerations}{3}}
\newlabel{section:rl_considerations}{{\unhbox \voidb@x \hbox {III-C}}{3}}
\newlabel{eq:reward_generation}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Performance Evaluation}{3}}
\newlabel{section:performance_evaluation}{{IV}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Simulation Parameters}{3}}
\newlabel{section:simulation_parameters}{{\unhbox \voidb@x \hbox {IV-A}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Optimal solution}{3}}
\newlabel{section:optimal_solution}{{\unhbox \voidb@x \hbox {IV-B}}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Simulation parameters\relax }}{3}}
\newlabel{tbl:simulation_parameters}{{I}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Optimal configurations (action indexes) to achieve the maximum network throughput and prop. fairness, resulting in 1124 Mbps and 891 Mbps, respectively. In parenthesis the analogous solution is shown. Actions indexes range from 1 to 8 and are mapped to (channel number, transmit power (dBm)): \{1,5\}, \{2,5\}, \{1,10\}, \{2,10\}, \{1,15\}, \{2,15\},\{1,20\} and \{2,20\}, respectively.\relax }}{3}}
\newlabel{tbl:optimal_configurations}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Input Parameters Analysis}{3}}
\newlabel{section:practical_analysis}{{\unhbox \voidb@x \hbox {IV-C}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Effect of $\alpha , \gamma $ and $\varepsilon _0$ in the average aggregate throughput ($100$ simulation runs per sample).\relax }}{4}}
\newlabel{fig:ql_alpha_gamma_epsilon_evaluation}{{1}{4}}
\newlabel{fig:alpha_vs_gamma_avg_tpt_sqrt_epsilon}{{2(a)}{4}}
\newlabel{sub@fig:alpha_vs_gamma_avg_tpt_sqrt_epsilon}{{(a)}{4}}
\newlabel{fig:alpha_vs_gamma_std_sqrt_epsilon}{{2(b)}{4}}
\newlabel{sub@fig:alpha_vs_gamma_std_sqrt_epsilon}{{(b)}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evaluation of $\alpha $ and $\gamma $.\relax }}{4}}
\newlabel{fig:ql_alpha_vs_gamma}{{2}{4}}
\newlabel{fig:e_1_a1_g095_ind_tpt}{{3(a)}{4}}
\newlabel{sub@fig:e_1_a1_g095_ind_tpt}{{(a)}{4}}
\newlabel{fig:e_1_a_1_g_095_ind_tpt}{{3(b)}{4}}
\newlabel{sub@fig:e_1_a_1_g_095_ind_tpt}{{(b)}{4}}
\newlabel{fig:e_1_a_01_g_005_ind_tpt}{{3(c)}{4}}
\newlabel{sub@fig:e_1_a_01_g_005_ind_tpt}{{(c)}{4}}
\newlabel{fig:e_01_a_01_g_005_ind_tpt}{{3(d)}{4}}
\newlabel{sub@fig:e_01_a_01_g_005_ind_tpt}{{(d)}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Individual throughput experienced by each WN during a single (10000 iterations) simulation run for different $\varepsilon _0$, $\alpha $ and $\gamma $.\relax }}{4}}
\newlabel{fig:ql_params_eval_individual_tpt}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusions }{4}}
\newlabel{section:conclusions}{{V}{4}}
\bibcite{nie1999qlearning}{1}
\bibcite{maghsudi2015joint}{2}
\bibcite{akella2007self}{3}
\bibcite{riihijarvi2005frequency}{4}
\bibcite{mhatre2007interference}{5}
\bibcite{bennis2010q}{6}
\bibcite{sutton1998reinforcement}{7}
\bibcite{watkins1992q}{8}
\bibcite{jain1999throughput}{9}
\bibcite{bellalta2016ax}{10}
\newlabel{fig:e1_a_1_g_0.95_avg_tpt}{{4(a)}{5}}
\newlabel{sub@fig:e1_a_1_g_0.95_avg_tpt}{{(a)}{5}}
\newlabel{fig:e_1_a_1_g_0.95_avg_tpt}{{4(b)}{5}}
\newlabel{sub@fig:e_1_a_1_g_0.95_avg_tpt}{{(b)}{5}}
\newlabel{fig:e_1_a_0.1_g_0.05_avg_tpt}{{4(c)}{5}}
\newlabel{sub@fig:e_1_a_0.1_g_0.05_avg_tpt}{{(c)}{5}}
\newlabel{fig:e_0.1_a_0.1_g_0.05_avg_tpt}{{4(d)}{5}}
\newlabel{sub@fig:e_0.1_a_0.1_g_0.05_avg_tpt}{{(d)}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Average throughput experienced by each WN during the last 5000 iterations of a total of 10000 iterations (in a single simulation run) and for different $\varepsilon _0$, $\alpha $ and $\gamma $.\relax }}{5}}
\newlabel{fig:ql_params_eval_average_tpt}{{4}{5}}
\newlabel{fig:e_1_a1_g095}{{5(a)}{5}}
\newlabel{sub@fig:e_1_a1_g095}{{(a)}{5}}
\newlabel{fig:e_1_a_1_g_095}{{5(b)}{5}}
\newlabel{sub@fig:e_1_a_1_g_095}{{(b)}{5}}
\newlabel{fig:e_1_a_01_g_005}{{5(c)}{5}}
\newlabel{sub@fig:e_1_a_01_g_005}{{(c)}{5}}
\newlabel{fig:e_01_a_01_g_005}{{5(d)}{5}}
\newlabel{sub@fig:e_01_a_01_g_005}{{(d)}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Probability of choosing the different actions at each WN for a single (10000 iterations) simulation run and different $\varepsilon _0$, $\alpha $ and $\gamma $ values\relax }}{5}}
\newlabel{fig:ql_params_eval_actions_prob}{{5}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
